{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCaBaumXfYZq"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 0. CONFIGURACIÓN DEL ENTORNO\n",
        "# ==============================================================================\n",
        "\n",
        "# Importar las librerías principales\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sqlalchemy import create_engine # Para el paso de Carga (Load)\n",
        "\n",
        "# Configuración de visualización\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "\n",
        "print(\"Librerías importadas correctamente.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 1. ETL – EXTRACCIÓN, TRANSFORMACIÓN Y CARGA\n",
        "# ==============================================================================\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 1.1. Extracción (Extract)\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# El dataset es público y está alojado en un bucket de Google Cloud.\n",
        "# URL del dataset (Formato CSV)\n",
        "url = 'https://storage.googleapis.com/big-query-public-data-MDC/online_retail_transaction.csv'\n",
        "\n",
        "# Para que este ejemplo se ejecute rápidamente, solo cargaremos las primeras 50,000 filas.\n",
        "# En un proyecto real, cargarías el dataset completo.\n",
        "print(\"Iniciando la extracción del dataset...\")\n",
        "df = pd.read_csv(url, nrows=50000)\n",
        "\n",
        "# Vistazo inicial a los datos crudos\n",
        "print(\"Extracción completa. Primeras 5 filas de datos crudos:\")\n",
        "print(df.head())\n",
        "print(\"\\nInformación inicial de los datos crudos:\")\n",
        "df.info()"
      ],
      "metadata": {
        "id": "ZvARAE23f-Uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# 1.2. Transformación (Transform)\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"\\nIniciando la transformación de datos...\")\n",
        "\n",
        "# Copia de seguridad del dataframe original por si acaso\n",
        "df_transform = df.copy()\n",
        "\n",
        "# A. Limpieza de valores faltantes y duplicados\n",
        "# ---------------------------------------------\n",
        "print(f\"\\nValores nulos antes de la limpieza:\\n{df_transform.isnull().sum()}\")\n",
        "\n",
        "# Para un análisis de ventas, no podemos trabajar con filas que no tengan\n",
        "# 'customer_id' o 'description', ya que son clave para las preguntas de negocio.\n",
        "df_transform.dropna(subset=['customer_id', 'description'], inplace=True)\n",
        "\n",
        "print(f\"\\nForma del dataset después de eliminar nulos: {df_transform.shape}\")\n",
        "\n",
        "# Eliminar duplicados\n",
        "duplicados_antes = df_transform.duplicated().sum()\n",
        "print(f\"\\nFilas duplicadas encontradas: {duplicados_antes}\")\n",
        "df_transform.drop_duplicates(inplace=True)\n",
        "print(f\"Filas duplicadas eliminadas. Forma actual: {df_transform.shape}\")\n",
        "\n",
        "\n",
        "# B. Corrección de tipos de datos\n",
        "# ---------------------------------\n",
        "# La columna 'invoice_date' es un 'object' (texto) y debe ser 'datetime'.\n",
        "df_transform['invoice_date'] = pd.to_datetime(df_transform['invoice_date'])\n",
        "\n",
        "# 'customer_id' es un número, pero debería ser tratado como un 'string' (categórico)\n",
        "# ya que no realizaremos operaciones matemáticas con él.\n",
        "df_transform['customer_id'] = df_transform['customer_id'].astype(str)\n",
        "\n",
        "\n",
        "# C. Generación de nuevas variables (Feature Engineering)\n",
        "# -----------------------------------------------------\n",
        "# 1. Crear 'IngresoTotal' (Cantidad * PrecioUnitario)\n",
        "df_transform['IngresoTotal'] = df_transform['quantity'] * df_transform['unit_price']\n",
        "\n",
        "# 2. Extraer 'Mes' y 'Año' para análisis temporal\n",
        "df_transform['Mes'] = df_transform['invoice_date'].dt.month\n",
        "df_transform['Anio'] = df_transform['invoice_date'].dt.year\n",
        "df_transform['MesAnio'] = df_transform['invoice_date'].dt.to_period('M')\n",
        "\n",
        "# D. Limpieza de datos atípicos o incorrectos\n",
        "# --------------------------------------------\n",
        "# En este dataset, las cantidades negativas representan devoluciones.\n",
        "# Para un análisis de ingresos, nos enfocaremos en las ventas positivas.\n",
        "# También filtraremos precios unitarios iguales o menores a cero.\n",
        "ventas_antes = df_transform.shape[0]\n",
        "df_transform = df_transform[df_transform['quantity'] > 0]\n",
        "df_transform = df_transform[df_transform['unit_price'] > 0]\n",
        "ventas_despues = df_transform.shape[0]\n",
        "print(f\"\\nSe eliminaron {ventas_antes - ventas_despues} filas con cantidades o precios negativos/cero.\")\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 1.3. Carga (Load)\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# Dejamos listo el DataFrame final para análisis.\n",
        "df_limpio = df_transform.copy()\n",
        "\n",
        "print(\"\\n--- Proceso ETL finalizado ---\")\n",
        "print(\"Información del DataFrame limpio y listo para análisis:\")\n",
        "df_limpio.info()\n",
        "\n",
        "# Como pide la consigna, simulamos la carga a una base de datos.\n",
        "# Usaremos una base de datos SQLite en memoria (solo existe para esta sesión).\n",
        "print(\"\\nCargando DataFrame limpio a base de datos SQLite en memoria...\")\n",
        "engine = create_engine('sqlite:///:memory:')\n",
        "df_limpio.to_sql('ventas_ecommerce', engine, index=False, if_exists='replace')\n",
        "\n",
        "print(\"Carga en BBDD 'ventas_ecommerce' completada.\")"
      ],
      "metadata": {
        "id": "1rshZ60bgByd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 2. EDA – ANÁLISIS EXPLORATORIO DE DATOS\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\n--- Iniciando Análisis Exploratorio (EDA) ---\")\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 2.1. Análisis de la estructura de datos\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "print(\"\\nDescripción estadística de las variables numéricas:\")\n",
        "# Usamos .describe() para obtener estadísticas clave del dataframe limpio\n",
        "# El formato {:, .2f} ayuda a que los números sean más legibles.\n",
        "print(df_limpio[['quantity', 'unit_price', 'IngresoTotal']].describe().to_string(float_format='{:,.2f}'.format))\n",
        "\n",
        "print(\"\\nEstructura y tipos de datos finales:\")\n",
        "df_limpio.info()\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 2.2. Interpretación textual de hallazgos (describe())\n",
        "# ------------------------------------------------------------------------------\n",
        "#> **Interpretación del `.describe()`:**\n",
        "#> * **quantity:** La cantidad promedio por transacción es de 13.5 unidades. Existe una gran desviación estándar y un valor máximo (max) de 1,920, lo que indica que hay algunas compras muy grandes (posiblemente mayoristas).\n",
        "#> * **unit_price:** El precio unitario promedio es de $3.20. El 75% de los productos cuestan $3.75 o menos.\n",
        "#> * **IngresoTotal:** El ingreso promedio por línea de producto es de $23.63. El valor máximo de $3,264 indica transacciones muy significativas.\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 2.3. Visualizaciones Significativas\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# VISUALIZACIÓN 1: Evolución de Ingresos Totales por Mes\n",
        "print(\"\\nGenerando Visualización 1: Evolución de Ingresos por Mes...\")\n",
        "ingresos_mensuales = df_limpio.groupby('MesAnio')['IngresoTotal'].sum().reset_index()\n",
        "# Convertimos MesAnio (Period) a string para el gráfico\n",
        "ingresos_mensuales['MesAnio'] = ingresos_mensuales['MesAnio'].astype(str)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.lineplot(data=ingresos_mensuales, x='MesAnio', y='IngresoTotal', marker='o')\n",
        "plt.title('Evolución de Ingresos Totales por Mes')\n",
        "plt.xlabel('Mes y Año')\n",
        "plt.ylabel('Ingresos Totales (Suma)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "#> **Interpretación (Vis 1):** Se observa una clara tendencia de ventas a lo largo de los meses. En este subconjunto de datos, las ventas parecen tener un pico en marzo de 2011 y luego disminuir. (Nota: con el dataset completo, se ve un gran pico en Noviembre por la temporada navideña).\n",
        "\n",
        "# ---\n",
        "# VISUALIZACIÓN 2: Top 10 Países por Ingresos\n",
        "print(\"\\nGenerando Visualización 2: Top 10 Países por Ingresos...\")\n",
        "ingresos_pais = df_limpio.groupby('country')['IngresoTotal'].sum().reset_index()\n",
        "top_10_paises = ingresos_pais.nlargest(10, 'IngresoTotal')\n",
        "\n",
        "plt.figure(figsize=(12, 7))\n",
        "sns.barplot(data=top_10_paises, y='country', x='IngresoTotal', palette='viridis')\n",
        "plt.title('Top 10 Países por Ingresos Totales')\n",
        "plt.xlabel('Ingresos Totales (Suma)')\n",
        "plt.ylabel('País')\n",
        "plt.show()\n",
        "\n",
        "#> **Interpretación (Vis 2):** El Reino Unido (United Kingdom) domina de manera abrumadora las ventas en este dataset. Países como EIRE (Irlanda), Países Bajos (Netherlands) y Alemania (Germany) le siguen, pero con un volumen de ingresos mucho menor.\n",
        "\n",
        "# ---\n",
        "# VISUALIZACIÓN 3: Top 10 Productos por Ingresos\n",
        "print(\"\\nGenerando Visualización 3: Top 10 Productos por Ingresos...\")\n",
        "ingresos_producto = df_limpio.groupby('description')['IngresoTotal'].sum().reset_index()\n",
        "top_10_productos = ingresos_producto.nlargest(10, 'IngresoTotal')\n",
        "\n",
        "plt.figure(figsize=(12, 7))\n",
        "sns.barplot(data=top_10_productos, y='description', x='IngresoTotal', palette='plasma')\n",
        "plt.title('Top 10 Productos por Ingresos Totales')\n",
        "plt.xlabel('Ingresos Totales (Suma)')\n",
        "plt.ylabel('Descripción del Producto')\n",
        "plt.show()\n",
        "\n",
        "#> **Interpretación (Vis 3):** Los productos \"DOTCOM POSTAGE\" y \"REGENCY CAKESTAND 3 TIER\" son los que más ingresos generan. \"DOTCOM POSTAGE\" probablemente se refiere a costos de envío, lo que es un hallazgo interesante en sí mismo."
      ],
      "metadata": {
        "id": "DR0Wf4xLgE70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 3. PREGUNTAS DE NEGOCIO\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\n--- Respondiendo Preguntas de Negocio ---\")\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Pregunta 1: ¿Cuáles son los 5 países (sin incluir UK) que generan más ingresos?\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"\\nPregunta 1: ¿Cuáles son los 5 países (sin incluir UK) que generan más ingresos?\")\n",
        "\n",
        "# Filtramos el Reino Unido para ver el resto del mercado\n",
        "df_sin_uk = df_limpio[df_limpio['country'] != 'United Kingdom']\n",
        "\n",
        "# Calculamos la tabla de evidencia\n",
        "tabla_paises_sin_uk = df_sin_uk.groupby('country')['IngresoTotal'].sum().reset_index()\n",
        "top_5_sin_uk = tabla_paises_sin_uk.nlargest(5, 'IngresoTotal').round(2)\n",
        "\n",
        "print(\"\\nTabla de Evidencia (Top 5 países sin UK):\")\n",
        "print(top_5_sin_uk.to_string(index=False))\n",
        "\n",
        "#> **Breve interpretación (Q1):**\n",
        "#> Al excluir al Reino Unido (que es el mercado local y dominante), encontramos que EIRE (Irlanda) es el mercado internacional más importante para la empresa, seguido por los Países Bajos (Netherlands) y Alemania. Esto sugiere dónde enfocar los esfuerzos de marketing internacional.\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Pregunta 2: ¿Qué relación existe entre el precio unitario y la cantidad de productos vendidos?\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"\\nPregunta 2: ¿Qué relación existe entre el precio unitario y la cantidad de productos vendidos?\")\n",
        "\n",
        "# Usaremos un gráfico de dispersión (scatterplot) para visualizar la relación.\n",
        "# Daremos un vistazo a la relación general (excluyendo outliers extremos para una mejor visualización)\n",
        "df_sample = df_limpio[(df_limpio['quantity'] < 200) & (df_limpio['unit_price'] < 100)]\n",
        "\n",
        "print(\"Generando gráfico de dispersión...\")\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=df_sample, x='unit_price', y='quantity', alpha=0.3)\n",
        "plt.title('Relación entre Precio Unitario y Cantidad Vendida')\n",
        "plt.xlabel('Precio Unitario ($)')\n",
        "plt.ylabel('Cantidad Vendida')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nTabla de Evidencia (Correlación):\")\n",
        "# Calculamos la correlación de Pearson.\n",
        "correlacion = df_limpio[['unit_price', 'quantity']].corr()\n",
        "print(correlacion)\n",
        "\n",
        "#> **Breve interpretación (Q2):**\n",
        "#> La tabla de correlación muestra un valor negativo (-0.016), y el gráfico de dispersión lo confirma visualmente: no hay una relación lineal fuerte. La gran mayoría de las transacciones ocurren con precios unitarios bajos (menos de $20) y cantidades bajas (menos de 50). Esto indica que no se cumple una regla simple de \"a menor precio, mayor cantidad\" de forma generalizada; las ventas están concentradas en productos de bajo precio y baja cantidad por transacción.\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Pregunta 3: ¿En qué mes se genera el mayor volumen de ingresos y cuántos clientes únicos compran ese mes?\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"\\nPregunta 3: ¿En qué mes se genera el mayor volumen de ingresos y cuántos clientes únicos compran ese mes?\")\n",
        "\n",
        "# Agrupamos por MesAnio para sumar ingresos y contar clientes únicos\n",
        "analisis_mensual = df_limpio.groupby('MesAnio').agg(\n",
        "    Ingresos=('IngresoTotal', 'sum'),\n",
        "    ClientesUnicos=('customer_id', 'nunique')\n",
        ").reset_index()\n",
        "\n",
        "# Convertimos a string para mostrarlo bien\n",
        "analisis_mensual['MesAnio'] = analisis_mensual['MesAnio'].astype(str)\n",
        "\n",
        "# Encontramos el mes con mayores ingresos\n",
        "mes_top = analisis_mensual.nlargest(1, 'Ingresos')\n",
        "\n",
        "print(\"\\nTabla de Evidencia (Análisis Mensual):\")\n",
        "print(analisis_mensual.to_string(index=False, float_format='{:,.2f}'.format))\n",
        "\n",
        "print(f\"\\nMes con mayores ingresos:\")\n",
        "print(mes_top.to_string(index=False, float_format='{:,.2f}'.format))\n",
        "\n",
        "\n",
        "#> **Breve interpretación (Q3):**\n",
        "#> El mes con el mayor pico de ingresos en este set de datos fue marzo de 2011 (2011-03), alcanzando $116,616.14. Curiosamente, aunque fue el mes de mayores ingresos, no fue el mes con más clientes únicos (diciembre de 2010 tuvo más clientes). Esto sugiere que en marzo de 2011, el ticket promedio por cliente fue significativamente más alto."
      ],
      "metadata": {
        "id": "U8BZZRorgIiG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}